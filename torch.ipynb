{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-20T08:55:19.419704Z",
     "start_time": "2025-08-20T08:55:19.400706Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sympy import false\n",
    "from sympy.abc import alpha\n",
    "from tensorflow.python.ops.linalg.linear_operator_algebra import inverse\n",
    "\n",
    "from datasetLoader import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from inverse import fit_linear\n",
    "\n",
    "from tools import model_tester\n",
    "from tools.reportParser import find_nearest\n",
    "%matplotlib qt"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:55:22.358277Z",
     "start_time": "2025-08-20T08:55:22.345278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "d322819b15356399",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:55:31.484666Z",
     "start_time": "2025-08-20T08:55:29.483635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pore_widths = np.load(\"data/initial kernels/new_kernel/pore_sizes.npy\")\n",
    "pressures = np.load(\"data/initial kernels/new_kernel/pressure.npy\")[:-14]\n",
    "kernel = np.load(\"data/initial kernels/new_kernel/new_kernel.npy\")[:, :-14]\n",
    "with open(\"data/initial kernels/new_kernel/new_kernel.npy\", 'rb') as f:\n",
    "    data_sorb = np.load(f)[:, :-14]\n",
    "\n",
    "x, y = load_dataset('data/datasets/carbon_random_normal_micro.npz', cut_end_idx=-14)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=1)\n",
    "\n",
    "x_exp, y_exp = load_dataset('data/datasets/exp.npz', cut_end_idx=-14)\n",
    "\n",
    "x_train_exp, x_test_exp, y_train_exp, y_test_exp = train_test_split(x_exp, y_exp, test_size=0.15, random_state=1)"
   ],
   "id": "d29956229295484c",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:55:34.164647Z",
     "start_time": "2025-08-20T08:55:32.170181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figure, axis = plt.subplots(3, 4)\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        k = np.random.randint(0, len(x_train_exp))\n",
    "        axis[i, j].plot(pressures[:], x_train_exp[k], marker=\".\")\n",
    "        #axis[i, j].set_xscale(\"log\")\n",
    "        ############################\n",
    "        start_i = 0\n",
    "        for l in range(len(x_train_exp[k])):\n",
    "            if x_train_exp[k][l] != 0:\n",
    "                start_i = l\n",
    "                break\n",
    "\n",
    "        end_i = len(x_train_exp[k])\n",
    "        for l in range(len(x_train_exp[k])-1, -1, -1):\n",
    "            if x_train_exp[k][l] != 1:\n",
    "                end_i = l+1\n",
    "                break\n",
    "\n",
    "        pd_test = fit_linear(x_train_exp[k][start_i:end_i], kernel[:, start_i:end_i], 0).x\n",
    "        tw = axis[i, j].twiny()\n",
    "        tw.plot(pore_widths, pd_test*100, color=\"r\", marker=\".\")\n",
    "\n",
    "        # dist = fit_linear(adsorption=isotherm_data[i][start_i:end_i], kernel=kernel[start_i:end_i], alpha=0).x\n",
    "        axis[i, j].plot(pressures[start_i:end_i], np.dot(pd_test, kernel)[start_i:end_i], marker=\".\")\n",
    "        ##############################\n",
    "        axis[i, j].grid()\n",
    "plt.show()"
   ],
   "id": "56cb2ebf581218f4",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:55:40.985678Z",
     "start_time": "2025-08-20T08:55:40.860172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figure, axis = plt.subplots(3, 4)\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        k = np.random.randint(0, len(y_train_exp))\n",
    "        axis[i, j].plot(pore_widths, y_train_exp[k], marker=\".\")\n",
    "        axis[i, j].grid()\n",
    "plt.show()"
   ],
   "id": "b92642b436f09b6e",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:55:43.124702Z",
     "start_time": "2025-08-20T08:55:43.002703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figure, axis = plt.subplots(3, 4)\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        k = np.random.randint(0, len(x_train))\n",
    "        axis[i, j].plot(pressures, x_train[k], marker=\".\")\n",
    "        axis[i, j].grid()\n",
    "plt.show()"
   ],
   "id": "56fc7f22da2e46d6",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:56:12.111151Z",
     "start_time": "2025-08-20T08:56:11.987152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figure, axis = plt.subplots(3, 4)\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        k = np.random.randint(0, len(x_train))\n",
    "        axis[i, j].plot(pore_widths, y_train[k], marker=\".\")\n",
    "        axis[i, j].grid()\n",
    "plt.show()"
   ],
   "id": "15f9ff24438da3f5",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:56:06.997993Z",
     "start_time": "2025-08-20T08:56:06.908476Z"
    }
   },
   "cell_type": "code",
   "source": "plt.plot(pore_widths, sum(y_train), marker=\".\")",
   "id": "d204e5d61104e3ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25e0156a470>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:38:45.815187Z",
     "start_time": "2025-08-20T05:38:45.047532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = np.random.randint(0, len(x_train))\n",
    "plt.plot(pressures[:-10], x_train[i], marker=\".\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "3201b1f78762f4ff",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (171,) and (181,)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m i \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(x_train))\n\u001B[1;32m----> 2\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpressures\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmarker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mgrid()\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\matplotlib\\pyplot.py:2767\u001B[0m, in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2765\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[0;32m   2766\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mplot\u001B[39m(\u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaley\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2767\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m gca()\u001B[38;5;241m.\u001B[39mplot(\n\u001B[0;32m   2768\u001B[0m         \u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39mscalex, scaley\u001B[38;5;241m=\u001B[39mscaley,\n\u001B[0;32m   2769\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1635\u001B[0m, in \u001B[0;36mAxes.plot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1393\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1394\u001B[0m \u001B[38;5;124;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[0;32m   1395\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1632\u001B[0m \u001B[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[0;32m   1633\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1634\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39mnormalize_kwargs(kwargs, mlines\u001B[38;5;241m.\u001B[39mLine2D)\n\u001B[1;32m-> 1635\u001B[0m lines \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lines(\u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n\u001B[0;32m   1636\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[0;32m   1637\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_line(line)\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001B[0m, in \u001B[0;36m_process_plot_var_args.__call__\u001B[1;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    310\u001B[0m     this \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    311\u001B[0m     args \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m--> 312\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:498\u001B[0m, in \u001B[0;36m_process_plot_var_args._plot_args\u001B[1;34m(self, tup, kwargs, return_kwargs)\u001B[0m\n\u001B[0;32m    495\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes\u001B[38;5;241m.\u001B[39myaxis\u001B[38;5;241m.\u001B[39mupdate_units(y)\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m--> 498\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y must have same first dimension, but \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    499\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhave shapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    500\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m y\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    501\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx and y can be no greater than 2D, but have \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    502\u001B[0m                      \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: x and y must have same first dimension, but have shapes (171,) and (181,)"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:38:48.337715Z",
     "start_time": "2025-08-20T05:38:48.239249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IsothermDataset(Dataset):\n",
    "    def __init__(self, isotherms, transform=None):\n",
    "        self.data = torch.tensor(isotherms, dtype=torch.float32).to(device)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, x\n",
    "\n",
    "x_mixed_train = np.concatenate((x_train_exp, x_train))\n",
    "x_mixed_test = np.concatenate((x_test_exp, x_test))\n",
    "\n",
    "# dataset = IsothermDataset(np.concatenate((x_train_exp, x_train_exp)))\n",
    "# dataset_test = IsothermDataset(np.concatenate((x_test_exp, x_test_exp)))\n",
    "dataset = IsothermDataset(np.concatenate((x_mixed_train, x_mixed_train)))\n",
    "dataset_test = IsothermDataset(np.concatenate((x_mixed_test, x_mixed_test)))\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ],
   "id": "5cefc1b65fc7fa63",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:38:49.052925Z",
     "start_time": "2025-08-20T05:38:49.049412Z"
    }
   },
   "cell_type": "code",
   "source": "y_exp[0].size",
   "id": "565056807e7f73b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:39:11.655366Z",
     "start_time": "2025-08-20T05:39:11.646861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, z\n",
    "\n",
    "input_dim = len(x_mixed_train[0])\n",
    "latent_dim = 16\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = Autoencoder(input_dim=input_dim, latent_dim=latent_dim)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train_autoencoder(model, loader, loader_test):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_vloss = 0\n",
    "    for x, _ in loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_recon, _ = model(x)\n",
    "        loss = criterion(x_recon, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, _ in loader_test:\n",
    "            x_recon, _  = model(x)\n",
    "            vloss = criterion(x_recon, x)\n",
    "            total_vloss += vloss.item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), total_vloss / len(loader_test.dataset)\n",
    "\n",
    "\n",
    "# sample_z = model.encoder(torch.tensor(isotherms_np[0], dtype=torch.float32))"
   ],
   "id": "c960463d00766e7c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:43:24.956224Z",
     "start_time": "2025-08-20T05:39:12.694108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    loss, vloss = train_autoencoder(model, loader,loader_test)\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss*100:.8f} Test loss: {vloss*100:.8f}\")"
   ],
   "id": "6f625ed77c7b7164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.00214626 Test loss: 0.00014176\n",
      "Epoch 2/200, Loss: 0.00009178 Test loss: 0.00006789\n",
      "Epoch 3/200, Loss: 0.00005339 Test loss: 0.00004523\n",
      "Epoch 4/200, Loss: 0.00003668 Test loss: 0.00003404\n",
      "Epoch 5/200, Loss: 0.00002900 Test loss: 0.00002643\n",
      "Epoch 6/200, Loss: 0.00002595 Test loss: 0.00002659\n",
      "Epoch 7/200, Loss: 0.00002441 Test loss: 0.00002443\n",
      "Epoch 8/200, Loss: 0.00002161 Test loss: 0.00001952\n",
      "Epoch 9/200, Loss: 0.00002043 Test loss: 0.00001754\n",
      "Epoch 10/200, Loss: 0.00001905 Test loss: 0.00002589\n",
      "Epoch 11/200, Loss: 0.00001761 Test loss: 0.00001458\n",
      "Epoch 12/200, Loss: 0.00001622 Test loss: 0.00001336\n",
      "Epoch 13/200, Loss: 0.00001539 Test loss: 0.00001349\n",
      "Epoch 14/200, Loss: 0.00001387 Test loss: 0.00001287\n",
      "Epoch 15/200, Loss: 0.00001321 Test loss: 0.00001159\n",
      "Epoch 16/200, Loss: 0.00001286 Test loss: 0.00001113\n",
      "Epoch 17/200, Loss: 0.00001192 Test loss: 0.00001194\n",
      "Epoch 18/200, Loss: 0.00001136 Test loss: 0.00000892\n",
      "Epoch 19/200, Loss: 0.00001065 Test loss: 0.00002256\n",
      "Epoch 20/200, Loss: 0.00001043 Test loss: 0.00002748\n",
      "Epoch 21/200, Loss: 0.00001003 Test loss: 0.00000784\n",
      "Epoch 22/200, Loss: 0.00000970 Test loss: 0.00000939\n",
      "Epoch 23/200, Loss: 0.00000978 Test loss: 0.00000819\n",
      "Epoch 24/200, Loss: 0.00000931 Test loss: 0.00000769\n",
      "Epoch 25/200, Loss: 0.00000845 Test loss: 0.00000737\n",
      "Epoch 26/200, Loss: 0.00000878 Test loss: 0.00000882\n",
      "Epoch 27/200, Loss: 0.00000830 Test loss: 0.00001358\n",
      "Epoch 28/200, Loss: 0.00000845 Test loss: 0.00000652\n",
      "Epoch 29/200, Loss: 0.00000791 Test loss: 0.00000664\n",
      "Epoch 30/200, Loss: 0.00000760 Test loss: 0.00000835\n",
      "Epoch 31/200, Loss: 0.00000770 Test loss: 0.00000586\n",
      "Epoch 32/200, Loss: 0.00000707 Test loss: 0.00000750\n",
      "Epoch 33/200, Loss: 0.00000716 Test loss: 0.00000967\n",
      "Epoch 34/200, Loss: 0.00000710 Test loss: 0.00000521\n",
      "Epoch 35/200, Loss: 0.00000618 Test loss: 0.00000544\n",
      "Epoch 36/200, Loss: 0.00000647 Test loss: 0.00000466\n",
      "Epoch 37/200, Loss: 0.00000632 Test loss: 0.00000595\n",
      "Epoch 38/200, Loss: 0.00000608 Test loss: 0.00000440\n",
      "Epoch 39/200, Loss: 0.00000605 Test loss: 0.00000453\n",
      "Epoch 40/200, Loss: 0.00000615 Test loss: 0.00000437\n",
      "Epoch 41/200, Loss: 0.00000602 Test loss: 0.00000477\n",
      "Epoch 42/200, Loss: 0.00000520 Test loss: 0.00000404\n",
      "Epoch 43/200, Loss: 0.00000557 Test loss: 0.00000457\n",
      "Epoch 44/200, Loss: 0.00000540 Test loss: 0.00000385\n",
      "Epoch 45/200, Loss: 0.00000519 Test loss: 0.00000593\n",
      "Epoch 46/200, Loss: 0.00000535 Test loss: 0.00000404\n",
      "Epoch 47/200, Loss: 0.00000533 Test loss: 0.00000348\n",
      "Epoch 48/200, Loss: 0.00000484 Test loss: 0.00000628\n",
      "Epoch 49/200, Loss: 0.00000500 Test loss: 0.00000329\n",
      "Epoch 50/200, Loss: 0.00000499 Test loss: 0.00000348\n",
      "Epoch 51/200, Loss: 0.00000505 Test loss: 0.00000392\n",
      "Epoch 52/200, Loss: 0.00000445 Test loss: 0.00000308\n",
      "Epoch 53/200, Loss: 0.00000483 Test loss: 0.00000856\n",
      "Epoch 54/200, Loss: 0.00000469 Test loss: 0.00000347\n",
      "Epoch 55/200, Loss: 0.00000441 Test loss: 0.00001152\n",
      "Epoch 56/200, Loss: 0.00000457 Test loss: 0.00000385\n",
      "Epoch 57/200, Loss: 0.00000460 Test loss: 0.00000460\n",
      "Epoch 58/200, Loss: 0.00000449 Test loss: 0.00000309\n",
      "Epoch 59/200, Loss: 0.00000431 Test loss: 0.00000299\n",
      "Epoch 60/200, Loss: 0.00000431 Test loss: 0.00000676\n",
      "Epoch 61/200, Loss: 0.00000436 Test loss: 0.00000298\n",
      "Epoch 62/200, Loss: 0.00000445 Test loss: 0.00000289\n",
      "Epoch 63/200, Loss: 0.00000390 Test loss: 0.00000285\n",
      "Epoch 64/200, Loss: 0.00000428 Test loss: 0.00000394\n",
      "Epoch 65/200, Loss: 0.00000405 Test loss: 0.00000572\n",
      "Epoch 66/200, Loss: 0.00000382 Test loss: 0.00000290\n",
      "Epoch 67/200, Loss: 0.00000400 Test loss: 0.00000425\n",
      "Epoch 68/200, Loss: 0.00000375 Test loss: 0.00000282\n",
      "Epoch 69/200, Loss: 0.00000418 Test loss: 0.00000315\n",
      "Epoch 70/200, Loss: 0.00000367 Test loss: 0.00000272\n",
      "Epoch 71/200, Loss: 0.00000361 Test loss: 0.00000443\n",
      "Epoch 72/200, Loss: 0.00000391 Test loss: 0.00000393\n",
      "Epoch 73/200, Loss: 0.00000373 Test loss: 0.00000291\n",
      "Epoch 74/200, Loss: 0.00000352 Test loss: 0.00000260\n",
      "Epoch 75/200, Loss: 0.00000368 Test loss: 0.00000814\n",
      "Epoch 76/200, Loss: 0.00000384 Test loss: 0.00000283\n",
      "Epoch 77/200, Loss: 0.00000346 Test loss: 0.00000246\n",
      "Epoch 78/200, Loss: 0.00000365 Test loss: 0.00000390\n",
      "Epoch 79/200, Loss: 0.00000337 Test loss: 0.00000309\n",
      "Epoch 80/200, Loss: 0.00000338 Test loss: 0.00000264\n",
      "Epoch 81/200, Loss: 0.00000360 Test loss: 0.00000698\n",
      "Epoch 82/200, Loss: 0.00000351 Test loss: 0.00000223\n",
      "Epoch 83/200, Loss: 0.00000336 Test loss: 0.00000580\n",
      "Epoch 84/200, Loss: 0.00000341 Test loss: 0.00000228\n",
      "Epoch 85/200, Loss: 0.00000323 Test loss: 0.00000292\n",
      "Epoch 86/200, Loss: 0.00000325 Test loss: 0.00000660\n",
      "Epoch 87/200, Loss: 0.00000324 Test loss: 0.00000224\n",
      "Epoch 88/200, Loss: 0.00000319 Test loss: 0.00000361\n",
      "Epoch 89/200, Loss: 0.00000321 Test loss: 0.00000248\n",
      "Epoch 90/200, Loss: 0.00000307 Test loss: 0.00000248\n",
      "Epoch 91/200, Loss: 0.00000298 Test loss: 0.00000188\n",
      "Epoch 92/200, Loss: 0.00000405 Test loss: 0.00000274\n",
      "Epoch 93/200, Loss: 0.00000239 Test loss: 0.00000283\n",
      "Epoch 94/200, Loss: 0.00000351 Test loss: 0.00000382\n",
      "Epoch 95/200, Loss: 0.00000266 Test loss: 0.00000185\n",
      "Epoch 96/200, Loss: 0.00000263 Test loss: 0.00000565\n",
      "Epoch 97/200, Loss: 0.00000316 Test loss: 0.00000174\n",
      "Epoch 98/200, Loss: 0.00000270 Test loss: 0.00000257\n",
      "Epoch 99/200, Loss: 0.00000283 Test loss: 0.00001165\n",
      "Epoch 100/200, Loss: 0.00000284 Test loss: 0.00000176\n",
      "Epoch 101/200, Loss: 0.00000314 Test loss: 0.00001203\n",
      "Epoch 102/200, Loss: 0.00000256 Test loss: 0.00000176\n",
      "Epoch 103/200, Loss: 0.00000260 Test loss: 0.00000216\n",
      "Epoch 104/200, Loss: 0.00000262 Test loss: 0.00000178\n",
      "Epoch 105/200, Loss: 0.00000262 Test loss: 0.00000173\n",
      "Epoch 106/200, Loss: 0.00000364 Test loss: 0.00000210\n",
      "Epoch 107/200, Loss: 0.00000227 Test loss: 0.00000173\n",
      "Epoch 108/200, Loss: 0.00000228 Test loss: 0.00000170\n",
      "Epoch 109/200, Loss: 0.00000251 Test loss: 0.00000159\n",
      "Epoch 110/200, Loss: 0.00000248 Test loss: 0.00000144\n",
      "Epoch 111/200, Loss: 0.00000242 Test loss: 0.00000146\n",
      "Epoch 112/200, Loss: 0.00000219 Test loss: 0.00000339\n",
      "Epoch 113/200, Loss: 0.00000319 Test loss: 0.00000416\n",
      "Epoch 114/200, Loss: 0.00000244 Test loss: 0.00000139\n",
      "Epoch 115/200, Loss: 0.00000225 Test loss: 0.00000174\n",
      "Epoch 116/200, Loss: 0.00000211 Test loss: 0.00000229\n",
      "Epoch 117/200, Loss: 0.00000267 Test loss: 0.00000126\n",
      "Epoch 118/200, Loss: 0.00000224 Test loss: 0.00000170\n",
      "Epoch 119/200, Loss: 0.00000201 Test loss: 0.00000328\n",
      "Epoch 120/200, Loss: 0.00000227 Test loss: 0.00000143\n",
      "Epoch 121/200, Loss: 0.00000249 Test loss: 0.00000196\n",
      "Epoch 122/200, Loss: 0.00000225 Test loss: 0.00000172\n",
      "Epoch 123/200, Loss: 0.00000287 Test loss: 0.00000174\n",
      "Epoch 124/200, Loss: 0.00000219 Test loss: 0.00000140\n",
      "Epoch 125/200, Loss: 0.00000208 Test loss: 0.00000222\n",
      "Epoch 126/200, Loss: 0.00000214 Test loss: 0.00000126\n",
      "Epoch 127/200, Loss: 0.00000214 Test loss: 0.00000141\n",
      "Epoch 128/200, Loss: 0.00000216 Test loss: 0.00000117\n",
      "Epoch 129/200, Loss: 0.00000206 Test loss: 0.00000328\n",
      "Epoch 130/200, Loss: 0.00000452 Test loss: 0.00000151\n",
      "Epoch 131/200, Loss: 0.00000184 Test loss: 0.00000150\n",
      "Epoch 132/200, Loss: 0.00000221 Test loss: 0.00000136\n",
      "Epoch 133/200, Loss: 0.00000221 Test loss: 0.00000331\n",
      "Epoch 134/200, Loss: 0.00000206 Test loss: 0.00000130\n",
      "Epoch 135/200, Loss: 0.00000192 Test loss: 0.00000153\n",
      "Epoch 136/200, Loss: 0.00000223 Test loss: 0.00000145\n",
      "Epoch 137/200, Loss: 0.00000189 Test loss: 0.00000120\n",
      "Epoch 138/200, Loss: 0.00000205 Test loss: 0.00000149\n",
      "Epoch 139/200, Loss: 0.00000207 Test loss: 0.00000167\n",
      "Epoch 140/200, Loss: 0.00000193 Test loss: 0.00000163\n",
      "Epoch 141/200, Loss: 0.00000196 Test loss: 0.00000113\n",
      "Epoch 142/200, Loss: 0.00000206 Test loss: 0.00000210\n",
      "Epoch 143/200, Loss: 0.00000221 Test loss: 0.00000354\n",
      "Epoch 144/200, Loss: 0.00000185 Test loss: 0.00000209\n",
      "Epoch 145/200, Loss: 0.00000234 Test loss: 0.00000140\n",
      "Epoch 146/200, Loss: 0.00000161 Test loss: 0.00000284\n",
      "Epoch 147/200, Loss: 0.00000182 Test loss: 0.00000117\n",
      "Epoch 148/200, Loss: 0.00000204 Test loss: 0.00000095\n",
      "Epoch 149/200, Loss: 0.00000193 Test loss: 0.00000143\n",
      "Epoch 150/200, Loss: 0.00000206 Test loss: 0.00000131\n",
      "Epoch 151/200, Loss: 0.00000177 Test loss: 0.00000116\n",
      "Epoch 152/200, Loss: 0.00000187 Test loss: 0.00000142\n",
      "Epoch 153/200, Loss: 0.00000178 Test loss: 0.00000127\n",
      "Epoch 154/200, Loss: 0.00000174 Test loss: 0.00000108\n",
      "Epoch 155/200, Loss: 0.00000185 Test loss: 0.00000116\n",
      "Epoch 156/200, Loss: 0.00000194 Test loss: 0.00000277\n",
      "Epoch 157/200, Loss: 0.00000188 Test loss: 0.00000328\n",
      "Epoch 158/200, Loss: 0.00000173 Test loss: 0.00000154\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     loss, vloss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_autoencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mloader_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.8f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Test loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvloss\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.8f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[14], line 43\u001B[0m, in \u001B[0;36mtrain_autoencoder\u001B[1;34m(model, loader, loader_test)\u001B[0m\n\u001B[0;32m     41\u001B[0m x_recon, _ \u001B[38;5;241m=\u001B[39m model(x)\n\u001B[0;32m     42\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(x_recon, x)\n\u001B[1;32m---> 43\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     45\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\torch\\_tensor.py:648\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    640\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    641\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    646\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    647\u001B[0m     )\n\u001B[1;32m--> 648\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    348\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    350\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 353\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    822\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    823\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    825\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    826\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    827\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:43:26.946686Z",
     "start_time": "2025-08-20T05:43:26.927547Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model, \"data/models/torch/autoencoder_exp.pt\")",
   "id": "6e5a9e294045c74c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:43:27.201505Z",
     "start_time": "2025-08-20T05:43:27.181483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torch.load(\"data/models/torch/autoencoder_exp.pt\", weights_only=False)\n",
    "model.eval()"
   ],
   "id": "f8af0cb897395d7c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=181, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=16, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=181, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:57:08.742054Z",
     "start_time": "2025-08-20T08:57:08.680057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "latent_vectors_train = model.encoder(torch.tensor(x_train, dtype=torch.float32).to(device)).detach().cpu().numpy()\n",
    "latent_vectors_test = model.encoder(torch.tensor(x_test, dtype=torch.float32).to(device)).detach().cpu().numpy()\n",
    "latent_vectors_test_exp = model.encoder(torch.tensor(x_test_exp, dtype=torch.float32).to(device)).detach().cpu().numpy()"
   ],
   "id": "59307777a8d5284",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:57:09.472569Z",
     "start_time": "2025-08-20T08:57:09.457570Z"
    }
   },
   "cell_type": "code",
   "source": "decoded = model.decoder(model.encoder(torch.tensor(x_test_exp, dtype=torch.float32).to(device))).detach().cpu().numpy()",
   "id": "a95fe3351e57df09",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:57:12.341323Z",
     "start_time": "2025-08-20T08:57:12.233328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figure, axis = plt.subplots(3, 3)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        k=np.random.randint(0, len(decoded))\n",
    "        axis[i, j].plot(pressures[:], x_test_exp[k], marker=\".\", label = \"origin\")\n",
    "        axis[i, j].plot(pressures[:], decoded[k], marker=\".\", label = \"decoded\")\n",
    "        axis[i, j].grid(True)\n",
    "axis[i, j].legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# k=np.random.randint(0, len(decoded))\n",
    "# plt.plot(pressures[:-10], x_test_exp[k], marker=\".\", label = \"origin\")\n",
    "# plt.plot(pressures[:-10], decoded[k], marker=\".\", label = \"decoded\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ],
   "id": "dbe5444885056917",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T09:49:59.729171Z",
     "start_time": "2025-07-09T09:49:59.069100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(0)\n",
    "labels = None \n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "latent_pca = pca.fit_transform(latent_vectors_train[:100])\n",
    "latent_pca_exp = pca.fit_transform(latent_vectors_test[:100])\n",
    "\n",
    "tsne = TSNE(n_components=2, init='pca', random_state=0)\n",
    "latent_tsne = tsne.fit_transform(latent_vectors_train[:100])\n",
    "latent_tsne_exp = tsne.fit_transform(latent_vectors_test[:100])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(latent_pca[:, 0], latent_pca[:, 1], label=\"train\")\n",
    "plt.scatter(latent_pca_exp[:, 0], latent_pca_exp[:, 1], label=\"exp\")\n",
    "plt.title(\"PCA of Latent Space\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(latent_tsne[:, 0], latent_tsne[:, 1], label=\"train\")\n",
    "plt.scatter(latent_tsne_exp[:, 0], latent_tsne_exp[:, 1], label=\"exp\")\n",
    "for i in range(latent_tsne_exp.shape[0]):\n",
    "        plt.text(latent_tsne_exp[i, 0], latent_tsne_exp[i, 1], str(i), fontsize=8, ha='center', va='center')\n",
    "plt.title(\"t-SNE of Latent Space\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "f578073be61beebe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anton\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:996: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anton\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anton\\PycharmProjects\\isotherm\\.venv\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:996: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:43:52.202408Z",
     "start_time": "2025-08-20T05:43:52.190898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_exact_idx_last(array, value):\n",
    "    flag = False\n",
    "    for i in range(len(array)):\n",
    "        if array[i] == value:\n",
    "            flag = True\n",
    "        if flag and array[i] != value:\n",
    "            return i\n",
    "def find_alpha(x_exp):\n",
    "    def triangle_method(log_residuals, log_solution_norms):\n",
    "        points = np.column_stack((log_residuals, log_solution_norms))\n",
    "        A = points[0]\n",
    "        B = points[-1]\n",
    "        AB = B - A\n",
    "        AB_norm = np.linalg.norm(AB)\n",
    "        dist = []\n",
    "        for i in range(0, len(points)):\n",
    "            P = points[i]\n",
    "            AP = P - A\n",
    "            dist.append(np.linalg.norm(np.cross(AB, AP)) / AB_norm)\n",
    "    \n",
    "        return dist\n",
    "    def calculate_roughness(psd, ord=2):\n",
    "        return np.linalg.norm(psd, ord=ord)\n",
    "\n",
    "    alpha_list = np.logspace(-3, 4, 40)\n",
    "    error_lst = []\n",
    "    roughness_lst = []\n",
    "    restored_isotherms = []\n",
    "    for alpha in alpha_list:\n",
    "        start_idx = find_exact_idx_last(x_exp, 0)\n",
    "        y = fit_linear(x_exp[start_idx:], kernel=data_sorb[:, start_idx:], alpha=alpha).x\n",
    "        restored_isotherm = np.dot(y, data_sorb)\n",
    "        restored_isotherms.append(restored_isotherm)\n",
    "        error_lst.append(np.linalg.norm((x_exp[start_idx:] - restored_isotherm[start_idx:]), ord=2))\n",
    "        roughness_lst.append(calculate_roughness(y))\n",
    "\n",
    "    dist = triangle_method(np.log(error_lst), np.log(roughness_lst))\n",
    "    alpha = alpha_list[np.argmax(dist)]\n",
    "    return alpha\n",
    "\n",
    "\n",
    "\n",
    "def plot_preds(x, y, preds): \n",
    "    NX, NY = 3, 4\n",
    "    figure, axis = plt.subplots(NX, NY)\n",
    "    for i in range(NX):\n",
    "        for j in range(NY):\n",
    "            \n",
    "            low_p = False\n",
    "            while low_p == False:\n",
    "                k = np.random.randint(0, len(preds))\n",
    "                for l in range(len(x[k])):\n",
    "                    if x[k][l]!=0:\n",
    "                        if pressures[l] < 1e-2:\n",
    "                            low_p = True\n",
    "                        break\n",
    "            \n",
    "            iso_axis = axis[i, j].twinx().twiny()\n",
    "            iso_axis.set_xlabel(\"P/P$^0$\",fontsize=8)\n",
    "            iso_axis.plot(pressures[:], x[k], label=\"Isotherm\", color = 'green')\n",
    "            kernel = (data_sorb.T[:])\n",
    "            iso_axis.plot(pressures[:], np.dot(kernel, preds[k][:]), label=\"Isotherm by model\", color=\"red\")\n",
    "            axis[i, j].set_title(f\"№ {k}\")\n",
    "            axis[i, j].title.set_size(10)\n",
    "            axis[i, j].grid()\n",
    "            axis[i, j].set_xlabel(\"nm\",fontsize=8)\n",
    "            axis[i, j].plot(pore_widths, (preds[k]), marker=\".\", label=f\"Model PSD\")\n",
    "            #axis[i, j].plot(pore_widths, y[k], marker=\".\", label=\"PSD\")\n",
    "            alpha = find_alpha(x[k])\n",
    "            start_idx = find_exact_idx_last(x[k], 0)\n",
    "            L_curve = fit_linear(x[k][start_idx:], kernel=data_sorb[:, start_idx:], alpha=alpha).x\n",
    "            axis[i, j].plot(pore_widths, L_curve, marker=\".\", label=\"L_curve\")\n",
    "            iso_axis.plot(pressures[:], np.dot(kernel, L_curve), label=\"Isotherm by L_curve\", color=\"yellow\")\n",
    "    plt.subplots_adjust(hspace=0.6, right=0.95, left=0.05, bottom=0.05, top=0.9)\n",
    "    plt.legend()\n",
    "    axis[0, 0].legend()\n",
    "    plt.show()"
   ],
   "id": "a07cbe66d234c80f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:43:53.151137Z",
     "start_time": "2025-08-20T05:43:53.128893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tools import model_tester\n",
    "from inverse import fit_linear\n",
    "\n",
    "error_lst, roughness_lst = model_tester.test_model_predictions(preds, x_test_exp, kernel=data_sorb[:, :-10])\n",
    "kde_x, kde_error, kde_fun = model_tester.calculate_kde_data(error_lst, stop=150)\n",
    "print(\"average error:\", np.mean(error_lst))\n",
    "plt.plot(kde_x, kde_error, label=model_name)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.plot()"
   ],
   "id": "1316a794fbe60afa",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtools\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m model_tester\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01minverse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m fit_linear\n\u001B[1;32m----> 4\u001B[0m error_lst, roughness_lst \u001B[38;5;241m=\u001B[39m model_tester\u001B[38;5;241m.\u001B[39mtest_model_predictions(\u001B[43mpreds\u001B[49m, x_test_exp, kernel\u001B[38;5;241m=\u001B[39mdata_sorb[:, :\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m10\u001B[39m])\n\u001B[0;32m      5\u001B[0m kde_x, kde_error, kde_fun \u001B[38;5;241m=\u001B[39m model_tester\u001B[38;5;241m.\u001B[39mcalculate_kde_data(error_lst, stop\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m150\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage error:\u001B[39m\u001B[38;5;124m\"\u001B[39m, np\u001B[38;5;241m.\u001B[39mmean(error_lst))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'preds' is not defined"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:56:39.494269Z",
     "start_time": "2025-08-20T08:56:39.480272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DynamicWeightAveraging:\n",
    "    def __init__(self, num_tasks, T=2.0):\n",
    "        self.num_tasks = num_tasks\n",
    "        self.T = T\n",
    "        self.loss_history = []  # список списков: [ [L1_1, L1_2, ...], [L2_1, L2_2, ...], ... ]\n",
    "\n",
    "    def update_weights(self):\n",
    "        if len(self.loss_history[0]) < 2:\n",
    "            return np.ones(self.num_tasks) / self.num_tasks\n",
    "\n",
    "        r = []\n",
    "        for i in range(self.num_tasks):\n",
    "            li = self.loss_history[i]\n",
    "            r_i = li[-1] / (li[-2] + 1e-8)\n",
    "            r.append(r_i)\n",
    "\n",
    "        r = np.array(r)\n",
    "        weights = self.T * np.exp(r / self.T)\n",
    "        weights /= weights.sum()\n",
    "        return weights\n",
    "\n",
    "    def append_losses(self, losses):  # losses — список текущих значений потерь [L1, L2, ...]\n",
    "        if not self.loss_history:\n",
    "            self.loss_history = [[] for _ in range(len(losses))]\n",
    "        for i, l in enumerate(losses):\n",
    "            self.loss_history[i].append(l)\n",
    "dwa = DynamicWeightAveraging(num_tasks=2)"
   ],
   "id": "8a3f50c19ae75247",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:56:40.014347Z",
     "start_time": "2025-08-20T08:56:39.971347Z"
    }
   },
   "cell_type": "code",
   "source": "dwa.update_weights()",
   "id": "64fc19dc8691f1e",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdwa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[43], line 8\u001B[0m, in \u001B[0;36mDynamicWeightAveraging.update_weights\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mupdate_weights\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_history\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_tasks) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_tasks\n\u001B[0;32m     11\u001B[0m     r \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:56:40.780346Z",
     "start_time": "2025-08-20T08:56:40.766346Z"
    }
   },
   "cell_type": "code",
   "source": "x_exp[0].size, y_exp[0].size",
   "id": "ad563994bc77112b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 117)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:57:23.886188Z",
     "start_time": "2025-08-20T08:57:23.825187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PSD_model(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(PSD_model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        psd = self.model(x)\n",
    "        return psd\n",
    "\n",
    "class Isotherm_PSD_Dataset(Dataset):\n",
    "    def __init__(self, x, y, original_x, transform=None):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "        self.original_x = torch.tensor(original_x, dtype=torch.float32).to(device)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        original_x = self.original_x[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y, original_x\n",
    "\n",
    "train_PSD = Isotherm_PSD_Dataset(latent_vectors_train, (y_train*100), x_train)\n",
    "test_PSD = Isotherm_PSD_Dataset(latent_vectors_test, (y_test*100), x_test)\n",
    "\n",
    "batch_size = 512\n",
    "PSD_loader = DataLoader(train_PSD, batch_size=batch_size, shuffle=True)\n",
    "PSD_loader_test = DataLoader(test_PSD, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "model_PSD = PSD_model(input_dim=latent_dim, output_dim=117)\n",
    "model_PSD.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model_PSD.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "with open(\"data/initial kernels/new_kernel/kernel.npy\", 'rb') as f:\n",
    "    data_sorb_torch = torch.tensor(np.load(f))\n",
    "    data_sorb_torch = data_sorb_torch.to(torch.float32).to(device)\n",
    "\n",
    "def isoterm_loss(predicted_y, x):\n",
    "    restored_isotherm = torch.matmul(predicted_y, data_sorb_torch)\n",
    "    loss = torch.mean((x - restored_isotherm) ** 2)\n",
    "    return loss\n",
    "\n",
    "def train_PSD_model(model, loader, loader_test):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_vloss = 0\n",
    "    for x, y, original_x in loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_recon = model(x)\n",
    "        loss = criterion(y_recon, y)\n",
    "        # iso_loss = isoterm_loss(y_recon, original_x)\n",
    "        # dwa.append_losses([loss.item(), iso_loss.item()])\n",
    "        # weights = dwa.update_weights()\n",
    "        # loss = weights[0] * loss + weights[1] * iso_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y, original_x in loader_test:\n",
    "            y_recon  = model(x)\n",
    "            vloss = criterion(y_recon, y)\n",
    "            # iso_loss = isoterm_loss(y_recon, original_x)\n",
    "            # vloss = weights[0] * vloss + weights[1] * iso_loss\n",
    "            total_vloss += vloss.item()\n",
    "\n",
    "    return total_loss / len(loader.dataset), total_vloss / len(loader_test.dataset)\n"
   ],
   "id": "e5e1fac9c7ab87a1",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:58:30.188141Z",
     "start_time": "2025-08-20T08:57:24.144696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 50\n",
    "loss_lst = []\n",
    "vloss_lst = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    loss, vloss = train_PSD_model(model_PSD, PSD_loader, PSD_loader_test)\n",
    "    loss_lst.append(loss)\n",
    "    vloss_lst.append(vloss)\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss*100:.8f} Test loss: {vloss*100:.8f}\")"
   ],
   "id": "2fd72aae7361b860",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.00022675 Test loss: 0.00013410\n",
      "Epoch 2/50, Loss: 0.00013061 Test loss: 0.00010035\n",
      "Epoch 3/50, Loss: 0.00010495 Test loss: 0.00008780\n",
      "Epoch 4/50, Loss: 0.00009240 Test loss: 0.00007332\n",
      "Epoch 5/50, Loss: 0.00008509 Test loss: 0.00007281\n",
      "Epoch 6/50, Loss: 0.00008120 Test loss: 0.00007144\n",
      "Epoch 7/50, Loss: 0.00007907 Test loss: 0.00006850\n",
      "Epoch 8/50, Loss: 0.00007690 Test loss: 0.00006757\n",
      "Epoch 9/50, Loss: 0.00007533 Test loss: 0.00006877\n",
      "Epoch 10/50, Loss: 0.00007485 Test loss: 0.00007159\n",
      "Epoch 11/50, Loss: 0.00007425 Test loss: 0.00006708\n",
      "Epoch 12/50, Loss: 0.00007243 Test loss: 0.00006410\n",
      "Epoch 13/50, Loss: 0.00007156 Test loss: 0.00006629\n",
      "Epoch 14/50, Loss: 0.00007063 Test loss: 0.00006547\n",
      "Epoch 15/50, Loss: 0.00006826 Test loss: 0.00006294\n",
      "Epoch 16/50, Loss: 0.00006695 Test loss: 0.00006622\n",
      "Epoch 17/50, Loss: 0.00006729 Test loss: 0.00006344\n",
      "Epoch 18/50, Loss: 0.00006575 Test loss: 0.00006420\n",
      "Epoch 19/50, Loss: 0.00006531 Test loss: 0.00006320\n",
      "Epoch 20/50, Loss: 0.00006496 Test loss: 0.00006177\n",
      "Epoch 21/50, Loss: 0.00006451 Test loss: 0.00006211\n",
      "Epoch 22/50, Loss: 0.00006413 Test loss: 0.00006295\n",
      "Epoch 23/50, Loss: 0.00006378 Test loss: 0.00006223\n",
      "Epoch 24/50, Loss: 0.00006325 Test loss: 0.00006362\n",
      "Epoch 25/50, Loss: 0.00006252 Test loss: 0.00006169\n",
      "Epoch 26/50, Loss: 0.00006375 Test loss: 0.00006223\n",
      "Epoch 27/50, Loss: 0.00006151 Test loss: 0.00005758\n",
      "Epoch 28/50, Loss: 0.00005682 Test loss: 0.00005768\n",
      "Epoch 29/50, Loss: 0.00005634 Test loss: 0.00005479\n",
      "Epoch 30/50, Loss: 0.00005636 Test loss: 0.00005727\n",
      "Epoch 31/50, Loss: 0.00005576 Test loss: 0.00005657\n",
      "Epoch 32/50, Loss: 0.00005571 Test loss: 0.00005548\n",
      "Epoch 33/50, Loss: 0.00005580 Test loss: 0.00005599\n",
      "Epoch 34/50, Loss: 0.00005524 Test loss: 0.00005650\n",
      "Epoch 35/50, Loss: 0.00005525 Test loss: 0.00005761\n",
      "Epoch 36/50, Loss: 0.00005472 Test loss: 0.00005559\n",
      "Epoch 37/50, Loss: 0.00005498 Test loss: 0.00005728\n",
      "Epoch 38/50, Loss: 0.00005464 Test loss: 0.00005542\n",
      "Epoch 39/50, Loss: 0.00005420 Test loss: 0.00005392\n",
      "Epoch 40/50, Loss: 0.00005382 Test loss: 0.00005570\n",
      "Epoch 41/50, Loss: 0.00005382 Test loss: 0.00005754\n",
      "Epoch 42/50, Loss: 0.00005372 Test loss: 0.00005765\n",
      "Epoch 43/50, Loss: 0.00005422 Test loss: 0.00005618\n",
      "Epoch 44/50, Loss: 0.00005326 Test loss: 0.00005487\n",
      "Epoch 45/50, Loss: 0.00005300 Test loss: 0.00005447\n",
      "Epoch 46/50, Loss: 0.00005306 Test loss: 0.00005683\n",
      "Epoch 47/50, Loss: 0.00005294 Test loss: 0.00005610\n",
      "Epoch 48/50, Loss: 0.00005268 Test loss: 0.00005635\n",
      "Epoch 49/50, Loss: 0.00005242 Test loss: 0.00005694\n",
      "Epoch 50/50, Loss: 0.00005238 Test loss: 0.00005699\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:58:38.816014Z",
     "start_time": "2025-08-20T08:58:38.776008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(loss_lst)\n",
    "plt.plot(vloss_lst)\n",
    "plt.show()"
   ],
   "id": "826613b63fcbd7f1",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:58:44.861346Z",
     "start_time": "2025-08-20T08:58:44.855346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"autoencoder_regressor_micro\"\n",
    "torch.save(model_PSD, f\"data/models/torch/{model_name}\") "
   ],
   "id": "8b63396d69bd925e",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:58:50.002834Z",
     "start_time": "2025-08-20T08:58:49.988832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"autoencoder_regressor_micro\"\n",
    "model_PSD = torch.load(f\"data/models/torch/{model_name}\", weights_only=False)"
   ],
   "id": "5df22fca0b595bb7",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:58:50.680097Z",
     "start_time": "2025-08-20T08:58:50.617097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_PSD.eval()\n",
    "y_train_PSD = model_PSD.model(torch.tensor(latent_vectors_train, dtype=torch.float32).to(device)).detach().cpu().numpy()\n",
    "y_test_PSD = model_PSD.model(torch.tensor(latent_vectors_test, dtype=torch.float32).to(device)).detach().cpu().numpy()\n",
    "y_test_exp_PSD = model_PSD.model(torch.tensor(latent_vectors_test_exp, dtype=torch.float32).to(device)).detach().cpu().numpy()"
   ],
   "id": "bd320d01dab9040b",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T08:59:36.412396Z",
     "start_time": "2025-08-20T08:58:51.105649Z"
    }
   },
   "cell_type": "code",
   "source": "plot_preds(x_test_exp, y_test_exp, y_test_exp_PSD/100)",
   "id": "424bd83f3fe2a9f9",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T06:55:32.132440Z",
     "start_time": "2025-08-16T06:55:32.121441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.savez(f\"data/models/metrics/{model_name}\", x=x_test_exp, y=y_test_exp_PSD)\n",
    "model_name\n"
   ],
   "id": "b11eabe3085b3dc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autoencoder_regressor'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89e0e8e7540ebf2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b5400f1a2ea29b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T09:56:27.468085Z",
     "start_time": "2025-07-10T09:56:27.447714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2 = \"autoencoder_regressor_combined\"\n",
    "model2_data = np.load(f\"data/models/metrics/{model2}.npz\")\n",
    "model2_x = model2_data[\"x\"]\n",
    "model2_y = model2_data[\"y\"]"
   ],
   "id": "ff4850d3c12aad63",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-10T09:57:49.497143Z",
     "start_time": "2025-07-10T09:56:28.082908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model2_y_math = [fit_linear(model2_x[i], data_sorb[:, :-10], 0).x for i in range(len(model2_x))]"
   ],
   "id": "d9638b31eec76efc",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T14:47:45.836216Z",
     "start_time": "2025-07-15T14:47:45.805216Z"
    }
   },
   "cell_type": "code",
   "source": "plot_preds(model2_x, model2_y_math, model2_y)",
   "id": "190a38ad01d9974d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[155], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m plot_preds(\u001B[43mmodel2_x\u001B[49m, model2_y_math, model2_y)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model2_x' is not defined"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b57282e80f242f36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T07:15:08.894169Z",
     "start_time": "2025-07-15T07:15:08.862561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/initial kernels/excel/kernel_N2_77K.csv\")"
   ],
   "id": "7d218eed32a5f654",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T07:15:09.860213Z",
     "start_time": "2025-07-15T07:15:09.844147Z"
    }
   },
   "cell_type": "code",
   "source": "pressures = data[\"# P/P0\\\\H[nm]\"]",
   "id": "6329324e18f5cd71",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T07:15:10.928378Z",
     "start_time": "2025-07-15T07:15:10.912497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a_array = []\n",
    "for i in (data.columns[1:]).to_numpy():\n",
    "    a_array.append(float(i))\n",
    "a_array = np.array(a_array)"
   ],
   "id": "adba2d4b571ef4d7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T07:15:11.792976Z",
     "start_time": "2025-07-15T07:15:11.779194Z"
    }
   },
   "cell_type": "code",
   "source": "new_kernel = data.to_numpy()",
   "id": "16cd3fe05cb482f9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T07:47:36.650309Z",
     "start_time": "2025-07-15T07:47:36.645799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.save(\"data/initial kernels/new_kernel/pressure.npy\", pressures)\n",
    "np.save(\"data/initial kernels/new_kernel/pore_sizes.npy\", a_array)\n",
    "np.save(\"data/initial kernels/new_kernel/kernel.npy\", new_kernel[:, 1:].T)"
   ],
   "id": "40dc6c7db073b0e0",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T07:47:12.647087Z",
     "start_time": "2025-07-15T07:47:12.640577Z"
    }
   },
   "cell_type": "code",
   "source": "new_kernel[:, 1:]",
   "id": "b55bbb0915d15841",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.95232682e+00, 3.73193260e+00, 3.32136295e+00, ...,\n",
       "        1.99026908e-04, 1.76855432e-04, 1.59128603e-04],\n",
       "       [4.19957099e+00, 3.94315055e+00, 3.55339145e+00, ...,\n",
       "        2.29265468e-04, 2.03725435e-04, 1.83305333e-04],\n",
       "       [4.42334610e+00, 4.19271427e+00, 3.78090471e+00, ...,\n",
       "        2.88698360e-04, 2.56537540e-04, 2.30823899e-04],\n",
       "       ...,\n",
       "       [1.53910509e+01, 1.49431184e+01, 1.45971719e+01, ...,\n",
       "        1.72948254e+01, 1.72948254e+01, 1.72948254e+01],\n",
       "       [1.53992906e+01, 1.49613487e+01, 1.45868859e+01, ...,\n",
       "        1.73099488e+01, 1.73099488e+01, 1.73099488e+01],\n",
       "       [1.53999701e+01, 1.49585595e+01, 1.45743595e+01, ...,\n",
       "        1.73115993e+01, 1.73115993e+01, 1.73115993e+01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "46e86efa1df2af42"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
